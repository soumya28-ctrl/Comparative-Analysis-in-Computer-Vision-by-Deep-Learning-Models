# Comparative-Analysis-in-Computer-Vision-by-Deep-Learning-Models
Deep learning and Machine Learning has been a major factor in the recent notable advance
ments in the field of computer vision. Because they are so good at extracting features from
 image data, Convolutional Neural Networks (CNNs) have long been the industry standard for
 image classification. A potent substitute in recent years has been Vision Transformers (ViTs),
 which are based on successful Transformer models in natural language processing and the key
 feature is the ViT whic h is self attention has brought the attention towards the computer vision
 . To comprehend global relationships within images, these models employ self-attention.
 This study examines three distinct neural network architectures for image classification
 using the MNIST dataset: a ”Local ViT” that employs shifted patches to potentially enhance
 local feature extraction, a standard Vision Transformer (ViT), and a conventional Convolutional
 Neural Network (CNN). To determine their strengths and shortcomings in identifying, we will
 assess their performance based on accuracy, loss, and classification errors.And the improve
ments brought in the exsiting problems 
